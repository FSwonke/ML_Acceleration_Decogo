Title of Concept
----------------
ML Acceleration for decogo

1 Background
------------

Describe
* Project background: motivation of the concept
* status quo of our software
* refer to existing documentation, if applicable

- subproblem solving contributes most to the runtime of process

- accelerating subproblem solving offers great potential to decrease runtime

- solving subproblems is finding new columns which minimize reduced cost

- reduced cost/dual solution "or" reduced cost direction is required to find new inner points

- to calculate an inner point from direction an external solver is called (ipopt(NLP)/scip(MINLP))



2 Functional description and non-functional requirements
--------------------------------------------------------

�WHAT�-Part

Describe the goal
* what this concept shall achieve (new or changed functionality)
* what constraints must be fulfilled (e.g. performance aspects)
Goals shall be verifiable such they can be tested in the end. If the verifiability is not obvious (e.g. �the size of the network shall be reduced substantially�), please consider how measurability of the targets can be achieved. Details, however, do not have to be described here. It suffices to take them into account when the tests are described below.

- Implementation of a machine learning algorithm to accelerate Decogo. This is achieved by training a neuronal network to predict feasible (inner) points from directions.

In Detail the following steps have to be fulfilled:

- Implementation of storing training data (direction, point)

- Implementation of training a Neuronal Network 

- Implementation of applying the neuronal Network

- Implementation of anomaly detection

3 Design and implementation outline
-----------------------------------

�HOW shall it work�-Part

Describe
* Class design
* (Public) Interfaces of classes
* Outline of the implementation (in cases when the implementation approach is a critical part of the overall solution, e.g., when a new, non-trivial algorithm shall be introduced)
* refer to existing documentation, if applicable

- Class Design for training data

    *Name: SubSolverData
        using a dictionary for storage and list of tuples
        Methods:
            def add_data(block_id, direction, point)
            def get_size(block_id)

- Class Design for training the neuronal network
*parallel insatances of init class from pyomo_minlp_model (input_model)
*from scikit-learn use: MLPClassifier, StandardScaler, train_test_split

    *Name: SurrogateModel
        Parameters:
            classifiers: dict, elemen: 
            block_ids
            scaling_parameters: dict, elemen: mean, var 
            binary_index: dict, elemen: list of binary index in a block
            split_test = 0.2 #uses 20% of accumlated data for validation
        Methods:
            def __init__(block_ids, binary_index) todo
                
                     self.clf_batch = dict, elem = NN for each block
                
                # init define block_ids, binary indexes
                     self.block_ids ...
                     self.binary_index = binary_index

            def init_train(block_id, training_data) todo
                #define the neuronal network
                #hidden layers
                #activation functions
                #solver

                # data from SubSolverData

                # read/split input and output data
                # uses split_data
                # preprocess input data -> scaled input output data
                    Sklearn.Preprocessing -> StandardScaler
                    self.scaler[block_id].transform(X)
                # initial training of the model -> fit self.clf_batch
                    self.clf_batch.fit(x, y)
                     
            def predict(block_id, direction) todo
                # read directions
                # directions as input for the ML_Model
                # preprocess input data -> standardize data
                    StandardScaler (Sklearn) 
                    transformed_direction = self.scaler[block_id].transform(direction)
                # make predictions, sklearn -> MLPClassifier.predict
                    prediction = self.clf_batch[block_id].predict(transformed_direction)
                # inverse transfrom standardization of output
                    inversetransfrom_pred = self.scaler[block_id].inversetransfrom(prediction)
                # return prediction
                # 
            
            
     
            def test_init_train(validation_data, block_id)      
                # predict with SurrogateModel
                # uses split_data method
                # 10th iteration -> enough data to call init_train
                # 15th iteration -> new data generated as validation_data
                # test with more/less data to see if SurrogateModel is working
                # show score, accuracy of SurrogateModel
                # generate Plots (see presentation)
            
            
            --------------------------------------------------------
            def update(block_id, training_data)                                    todo
                # accumulate more training data and update model
                # 

            def update_model_specifications()     

            def split_data(block_id, training_data, test = False)
                # splits training/test data (dictionary) into input/output - arrays
                # param: X; nd array (n_samples, n_features)
                # param: y; nd array (n_samples, n_outputs)
                # 
                # -> if test = false: no split between training and validation data happens
                # -> if test = true: data is splitted in 80% training and 20% validation
                
                returns X, y   

            def ml_sub_solve(block_id, direction)
                # reads direction from master problem
                # transfrom into orig space
                # makes prediction        



- Class Design for using the neuronal network
     
     - add SurrogateModel as parameter in
     class decogo.pyomo_minlp_model.input_model.PyomoSubProblems(sub_models, cuts, block_id, settings)
     
      --method:
        def ml_sub_solver_init_train()
            call SurrogateModel.init_train()
        def ml_sub_solver_test_init_train() 
    -----------------------------------done
     - add methods to
     class decogo.solver.refactory_colgen.RefactoryColGen(problem, settings, result)
        
        def ml_sub_solver_init()
            call SubProblems.ml_sub_solver_init_train() for all blocks
            
        def ml_sub_solver_test()
             call ml_sub_solver_test_init_train()
        
        -------------------------------
        def ml_sub_solver_update()
        
        
     
     - call ml_sub_solver_init() and ml_sub_solver_test() in solve() in the main iterations:
        ------------------------------------
          while True:
            self.result.main_iterations += 1
         -----------------------------------
         
     
     
     
     
     
     Class MLSubSolver
    *Name: "predictinnerpoint"
        Parameters:
            SurrogateModel

        Methods:
            def __init__()

            def predict(direction)
                SurrogateModel.predict()
                #uses the NN to predcit point
                
            def verfication()
                #evaulates if prediction made by the model is right/wrong

- class design for applying anomaly detection



4 Critical implementation details
---------------------------------

�HOW shall I do it�-Part

Describe details of the implementation.

This section can be kept very short or can even be empty if the implementation is considered to be clear enough for the developers because
* No major difficulties are expected and
* The developer is sufficiently familiar with the corresponding part of the software


- Class Design for training the neuronal network

      Implementation details of classifiers: todo



5 Test concept and execution summary
------------------------------------

This section must be updated and handed in for review by the developer when an activity is about to be published. In the end (after test execution), it shall describe all tests which shall be executed in addition to the mandatory publish tests and briefly summarize their results. The objective is not to have a detailed, reproducible test execution protocol but a brief indication about the nature and the level of detail of the tests such that the reviewer can judge whether the amount of testing is sufficient for the risk and complexity of the work package.
Additional or adapted unit tests
Brief summary suffices. Details referring to the implementation shall be described together with the concept for the production code.
Regression tests from the test suite
List standard regression test cases in our test suite. Explain if a more detailed analysis shall be done (beyond checking that the overall test passed).
Additional (manual) tests
Please list any other tests that need to be executed. Examples:
* Manually constructed small examples where the result has been precalculated.
* Detailed comparison (diff etc.) of two runs where a certain feature was switched on and off
* Detailed log file
* Performance tests on a dedicated environment to measure the speed up achieved by a feature.
* Profiling, Memory tests

6 Activity descriptions: coding, documentation and testing
----------------------------------------------------------

Devide the concept into activities.

26.11.2021      finished coding init_train, predict
                Wednesday -> code test_init_train, test
                Friday -> update_SurrogateMOdel
3.12.2021       aim to finish testing init_train, predict; code update_SurrogateMOdel, how to pass in training_data to SurrogateModel
                done:
                coding test_init_train
                update Surrogate_model
                how to pass in training_data
                training the surrogate model for some iterations
                testing the Surrogate_model after some iterations

7 plan & milestones: (2 days per week)
-----------------------------------------------------------

* implement surrogate model in sub-problem solving (init_train & update surrogate model & test)                    2021.11 (2 weeks)  

* implement ml-sub-solver with surrogate model (integration of surrogate model and other local sub-solver & test)  2021.12 (3 weeks)

* implement evaluator (anormly detection & test)                                                                   2021.12 - 2022.1 (2 weeks)

* tune overall ml-sub-solving (test & tune surrogate model/anormly detection model & extra test of algorithm )     2022.1 - 2022.2 (4 weeks)




