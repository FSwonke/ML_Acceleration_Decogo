Title of Concept
----------------
ML Acceleration for decogo

1 Background
------------

Describe
* Project background: motivation of the concept
* status quo of our software
* refer to existing documentation, if applicable

- subproblem solving contributes most to the runtime of process

- accelerating subproblem solving offers great potential to decrease runtime

- solving subproblems is finding new columns which minimize reduced cost

- reduced cost/dual solution "or" reduced cost direction is required to find new inner points

- to calculate an inner point from direction an external solver is called (ipopt(NLP)/scip(MINLP))



2 Functional description and non-functional requirements
--------------------------------------------------------

�WHAT�-Part

Describe the goal
* what this concept shall achieve (new or changed functionality)
* what constraints must be fulfilled (e.g. performance aspects)
Goals shall be verifiable such they can be tested in the end. If the verifiability is not obvious (e.g. �the size of the network shall be reduced substantially�), please consider how measurability of the targets can be achieved. Details, however, do not have to be described here. It suffices to take them into account when the tests are described below.

- Implementation of a machine learning algorithm to accelerate Decogo. This is achieved by training a neuronal network to predict feasible (inner) points from directions.

In Detail the following steps have to be fulfilled:

- Implementation of storing training data (direction, point)

- Implementation of training a Neuronal Network 

- Implementation of applying the neuronal Network

- Implementation of anomaly detection

3 Design and implementation outline
-----------------------------------

�HOW shall it work�-Part

Describe
* Class design
* (Public) Interfaces of classes
* Outline of the implementation (in cases when the implementation approach is a critical part of the overall solution, e.g., when a new, non-trivial algorithm shall be introduced)
* refer to existing documentation, if applicable

- Class Design for training data

    *Name: SubSolverData
        using a dictionary for storage and list of tuples
        Methods:
            def add_data(block_id, direction, point)
            def get_size(block_id)

- Class Design for training the neuronal network
*parallel insatances of init class from pyomo_minlp_model (input_model)
*from scikit-learn use: MLPClassifier, StandardScaler, train_test_split

    *Name: SurrogateModel
        Parameters:
            
            block_id: integer
            binary_index: dict, elemen: list of binary index in a block
            
        Methods:
            def __init__(block_id, binary_index) 
                
                self.clf_batch = {} 'dict, elem = NN for each block
                self.scaler = {} ' scaler for each block
                self.block_id = block_id
                self.binary_index = binary_index
                self.test_split = ### ' preset train/test ratio

            def init_train(block_id, training_data) 
                # data from SubSolverData (training_data)
                #define the neuronal network
                #hidden layers, activation functions, solver, loss
                #Tensorflow package
                              
                X_train, y_train = self.split_data(block_id, training data, test = False)     'read/split input and output data
                
                # preprocess input data -> scaled input output data
                #Sklearn.Preprocessing -> StandardScaler (Sklearn)
                self.scaler[block_id] = StandardScaler().fit(X_train, y_train)
                X_scaled = self.scaler[block_id].transform(X_train)

                # initial training of the model tensorflow sequential.fit
                self.clf_batch.fit(x, y)
                     
            def predict(block_id, direction) todo
                # read directions (orig_space)
                # directions as input for the ML_Model

                # preprocess input data -> standardize data
                    
                transformed_direction = self.scaler[block_id].transform(direction)

                # make predictions, tensorflow -> Sequential.predict
                prediction = self.clf_batch[block_id].predict(transformed_direction)
                
                # round prediction to no digit binaries (0,1)
                prediction = np.around(prediction)

                return prediction
                 
            
            
     
            def test_init_train(block_id, training_data)      
                # predict with SurrogateModel
                # uses split_data method
                X_test, y_test = self.split_data(block_id, training data, test = True) 
                
                pred = self.predict(block_id, X_test, y_test)

                return pred
            
               

            def split_data(block_id, training_data, test = False)
                # splits training/test data (dictionary) into input/output - arrays
                # param: X; nd array (n_samples, n_features)
                # param: y; nd array (n_samples, n_outputs)
                # 
                # -> if test = false: no split between training and validation data happens
                # -> if test = true: data is splitted in 80% training and 20% validation
                
                returns X, y   

            def ml_sub_solve(block_id, direction, point, x_ia)
                # reads direction from master problem
                # point: feasible point from global subsolver
                # x_ia: primal solution from LP-IA Masterproblem -> starting point for NLP-Solver
                # 
                # make prediction   
                pred = self.prediction(block_id, direction)   

                # build vector with new prediction as input for NLP-Solver -> X
                # easy comparison between pred (Surrogate_model) and p (global subsolver)
                # similarly x and point, but as fully set up vector with bin and cont variables

                return pred, p, x, point  



- Class Design for using the neuronal network
     
     - add SurrogateModel as parameter in
     class decogo.pyomo_minlp_model.input_model.PyomoSubProblems(sub_models, cuts, block_id, settings)
     
      --method:
        def ml_sub_solver_init_train()
            call SurrogateModel.init_train()
        def ml_sub_solver_test_init_train() 
    -----------------------------------done
     - add methods to
     class decogo.solver.refactory_colgen.RefactoryColGen(problem, settings, result)
        
        def ml_sub_solver_init()
            call SubProblems.ml_sub_solver_init_train() for all blocks
            
        def ml_sub_solver_test()
             call ml_sub_solver_test_init_train()
        
        -------------------------------
        def ml_sub_solver_update()
        
        
     
     - call ml_sub_solver_init() and ml_sub_solver_test() in solve() in the main iterations:
        ------------------------------------
          while True:
            self.result.main_iterations += 1
         -----------------------------------

         

    Class RefactoryColGen
        # add method anomaly_detection (decide whether to call global solver [subproblem])
        # add method eval_prediction (call global solve and compare to prediction -> decide if to update model [refactory_colgen])
        # add method update_model

     def evaluate_pred(self,direction, y_clf):

            # direction from column generation
            # y_clf : prediction from surrogate model

            #transfrom input (direction) with block-dependent scaler
            #call chi2_test to find outlier and return boolean value (update_model)
            # if outlier
            #   update_model == True
            # else 
            #   update_model = False
            #apply local_nlp_solve(direction) -> check if predicted binaries contribute to a smaller obj_value
            #calc min inner point
            #compare obj_values from predicted and current point and decide if model has to be updated
            # if new_point == True
            #   if obj_value_new < obj_value
                    #update_model = False


            #return update_model, new_point
            pass
     
     
     
     
     Class MLSubSolver
    *Name: "predictinnerpoint"
        Parameters:
            SurrogateModel

        Methods:
            def __init__()

            def predict(direction)
                SurrogateModel.predict()
                #uses the NN to predcit point
                
            def verfication()
                #evaulates if prediction made by the model is right/wrong

    

- class design for applying anomaly detection
class anomaly_detection:

    def __init__(self,):

        self.pca_model = {}

    def hoteling_t2(self,direction, x, dof):
        # takes tranformed direction t_n
        # chi2 distribution from scipy.stats
        # calc mean, variance of the direction
        # np.mean(), np.var()
        # determine the test statistic for a t test (y_score) 
        # stats.chi2.cdf(y_score, df) 'returns probability for a given test statistic
        # compute y_prob from chi2 cdf
        # define anomaly threshold, define confidence interval q (level of reliability)
        # stats.chi2.ppf(q,df) 'inverse of cdf returns score for given probability
        # if y_prob > anomaly threshold
        #   t2_bools = True
        # else
        #   t2_bools = False
        #
        #return t2_bools
        pass

    

    def local_nlp_solve(self, direction, x_k):
        # direction from CG
        # x_k starting point for local solver

        # new point : boolean
        # y_tilde: point (ndarray)
        # obj_value: number (float)

        #return new_point, y_tilde, obj_value
        pass

    def get_min_inner_point(self,dir_orig_space):
        # calculates the obj_value d^T*x , Dot Product of direction and point
        #return obj_value
        pass



4 Critical implementation details
---------------------------------

�HOW shall I do it�-Part

Describe details of the implementation.

This section can be kept very short or can even be empty if the implementation is considered to be clear enough for the developers because
* No major difficulties are expected and
* The developer is sufficiently familiar with the corresponding part of the software


- Class Design for training the neuronal network

      Implementation details of classifiers: todo



5 Test concept and execution summary
------------------------------------

This section must be updated and handed in for review by the developer when an activity is about to be published. In the end (after test execution), it shall describe all tests which shall be executed in addition to the mandatory publish tests and briefly summarize their results. The objective is not to have a detailed, reproducible test execution protocol but a brief indication about the nature and the level of detail of the tests such that the reviewer can judge whether the amount of testing is sufficient for the risk and complexity of the work package.
Additional or adapted unit tests
Brief summary suffices. Details referring to the implementation shall be described together with the concept for the production code.
Regression tests from the test suite
List standard regression test cases in our test suite. Explain if a more detailed analysis shall be done (beyond checking that the overall test passed).
Additional (manual) tests
Please list any other tests that need to be executed. Examples:
* Manually constructed small examples where the result has been precalculated.
* Detailed comparison (diff etc.) of two runs where a certain feature was switched on and off
* Detailed log file
* Performance tests on a dedicated environment to measure the speed up achieved by a feature.
* Profiling, Memory tests

6 Activity descriptions: coding, documentation and testing
----------------------------------------------------------

Devide the concept into activities.

26.11.2021      finished coding init_train, predict
                Wednesday -> code test_init_train, test
                Friday -> update_SurrogateMOdel
3.12.2021       aim to finish testing init_train, predict; code update_SurrogateMOdel, how to pass in training_data to SurrogateModel
                done:
                coding test_init_train
                update Surrogate_model
                how to pass in training_data
                training the surrogate model for some iterations
                testing the Surrogate_model after some iterations
12.01.2022      more advanced graphics -> display from what phase training data comes (ia_init, approx_colgen, fwcolgen)

19.01.2022      Design Experiments (Different amount of training/test data & leaving out data (e.g from ia_init, approx colgen))
                start working on evaluator (first -> proposal in concept file)

7 plan & milestones: (2 days per week)
-----------------------------------------------------------

* implement surrogate model in sub-problem solving (init_train & update surrogate model & test)                    2021.11 (2 weeks)  

* implement ml-sub-solver with surrogate model (integration of surrogate model and other local sub-solver & test)  2021.12 (3 weeks)

* implement evaluator (anormly detection & test)                                                                   2021.12 - 2022.1 (2 weeks)

* tune overall ml-sub-solving (test & tune surrogate model/anormly detection model & extra test of algorithm )     2022.1 - 2022.2 (4 weeks)




